{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d5f6b9",
   "metadata": {},
   "source": [
    "## Phase 4 ‚Äî Multi-Aspect Judge with Reference Answers\n",
    "\n",
    "\n",
    "Judge evaluates against reference answer and custom rubrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23e0eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "MODEL_ANSWER = \"gpt-4o-mini\"   # responder\n",
    "MODEL_JUDGE  = \"gpt-4.1\"        # judge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a68546",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvaluationRubric:\n",
    "    \"\"\"Define evaluation criteria\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    weight: float = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecace3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import M\n",
    "\n",
    "\n",
    "class MultiAspectJudge:\n",
    "    \"\"\"Advanced judge with reference answers and custom rubrics\"\"\"\n",
    "    \n",
    "    def __init__(self, rubrics: List[EvaluationRubric] = None):\n",
    "        self.rubrics = rubrics or self._default_rubrics()\n",
    "    \n",
    "    def _default_rubrics(self) -> List[EvaluationRubric]:\n",
    "        \"\"\"Default evaluation rubrics\"\"\"\n",
    "        return [\n",
    "            EvaluationRubric(\"accuracy\", \"Factual correctness and precision\", 2.0),\n",
    "            EvaluationRubric(\"completeness\", \"Coverage of all relevant aspects\", 1.5),\n",
    "            EvaluationRubric(\"clarity\", \"Clear and understandable explanation\", 1.0),\n",
    "            EvaluationRubric(\"coherence\", \"Logical flow and organization\", 1.0),\n",
    "            EvaluationRubric(\"conciseness\", \"Appropriate length without redundancy\", 0.8)\n",
    "        ]\n",
    "    \n",
    "    def generate_answer(self, question: str, context: str = \"\") -> str:\n",
    "        \"\"\"Generate an answer\"\"\"\n",
    "        prompt = f\"{context}\\n\\nQuestion: {question}\" if context else question\n",
    "        \n",
    "        message = client.chat.completions.create(\n",
    "            model=MODEL_ANSWER,\n",
    "            max_tokens=1000,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return message.choices[0].message.content\n",
    "    \n",
    "    def evaluate_with_reference(\n",
    "        self, \n",
    "        question: str, \n",
    "        candidate_answer: str,\n",
    "        reference_answer: Optional[str] = None,\n",
    "        context: str = \"\"\n",
    "    ) -> Dict:\n",
    "        \"\"\"Evaluate answer against reference and rubrics\"\"\"\n",
    "        \n",
    "        # Build rubric description\n",
    "        rubric_text = \"\\n\".join([\n",
    "            f\"- {r.name.capitalize()} (weight: {r.weight}): {r.description}\"\n",
    "            for r in self.rubrics\n",
    "        ])\n",
    "        \n",
    "        reference_section = \"\"\n",
    "        if reference_answer:\n",
    "            reference_section = f\"\"\"\n",
    "Reference Answer (gold standard):\n",
    "{reference_answer}\n",
    "\n",
    "Compare the candidate answer to this reference.\n",
    "\"\"\"\n",
    "        \n",
    "        context_section = \"\"\n",
    "        if context:\n",
    "            context_section = f\"\"\"\n",
    "Context/Background:\n",
    "{context}\n",
    "\"\"\"\n",
    "        \n",
    "        judge_prompt = f\"\"\"You are an expert evaluator assessing an answer's quality.\n",
    "\n",
    "{context_section}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Candidate Answer:\n",
    "{candidate_answer}\n",
    "\n",
    "{reference_section}\n",
    "\n",
    "Evaluation Rubrics:\n",
    "{rubric_text}\n",
    "\n",
    "For each rubric criterion, provide:\n",
    "1. Score (1-10)\n",
    "2. Brief justification\n",
    "\n",
    "Also provide:\n",
    "- Overall weighted score\n",
    "- Key strengths (2-3 points)\n",
    "- Key weaknesses (2-3 points)\n",
    "- Specific suggestions for improvement\n",
    "- Alignment with reference (if provided): percentage 0-100\n",
    "\n",
    "Respond ONLY with valid JSON:\n",
    "{{\n",
    "    \"rubric_scores\": {{\n",
    "        \"accuracy\": {{\"score\": <number>, \"justification\": \"...\"}},\n",
    "        \"completeness\": {{\"score\": <number>, \"justification\": \"...\"}},\n",
    "        \"clarity\": {{\"score\": <number>, \"justification\": \"...\"}},\n",
    "        \"coherence\": {{\"score\": <number>, \"justification\": \"...\"}},\n",
    "        \"conciseness\": {{\"score\": <number>, \"justification\": \"...\"}}\n",
    "    }},\n",
    "    \"weighted_score\": <number>,\n",
    "    \"raw_average\": <number>,\n",
    "    \"reference_alignment\": <number or null>,\n",
    "    \"strengths\": [\"strength1\", \"strength2\"],\n",
    "    \"weaknesses\": [\"weakness1\", \"weakness2\"],\n",
    "    \"improvements\": [\"suggestion1\", \"suggestion2\"],\n",
    "    \"overall_assessment\": \"detailed paragraph\"\n",
    "}}\n",
    "\"\"\"\n",
    "        \n",
    "        message = client.chat.completions.create(\n",
    "            model=MODEL_JUDGE,\n",
    "            max_tokens=2000,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": judge_prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        response_text = message.choices[0].message.content\n",
    "        \n",
    "        try:\n",
    "            if \"```json\" in response_text:\n",
    "                response_text = response_text.split(\"```json\")[1].split(\"```\")[0]\n",
    "            elif \"```\" in response_text:\n",
    "                response_text = response_text.split(\"```\")[1].split(\"```\")[0]\n",
    "            \n",
    "            return json.loads(response_text.strip())\n",
    "        except json.JSONDecodeError:\n",
    "            return {\n",
    "                \"error\": \"Failed to parse JSON\",\n",
    "                \"raw_response\": response_text\n",
    "            }\n",
    "    \n",
    "    def batch_evaluate(\n",
    "        self, \n",
    "        questions: List[str],\n",
    "        candidate_answers: List[str],\n",
    "        reference_answers: Optional[List[str]] = None\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Evaluate multiple Q&A pairs\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i, (question, candidate) in enumerate(zip(questions, candidate_answers)):\n",
    "            reference = reference_answers[i] if reference_answers else None\n",
    "            evaluation = self.evaluate_with_reference(question, candidate, reference)\n",
    "            results.append({\n",
    "                \"question\": question,\n",
    "                \"evaluation\": evaluation\n",
    "            })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58de7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_detailed_evaluation(eval_result: Dict):\n",
    "    \"\"\"Pretty print detailed evaluation\"\"\"\n",
    "    if \"error\" in eval_result:\n",
    "        print(f\"‚ùå Error: {eval_result['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üìä DETAILED EVALUATION REPORT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Scores by rubric\n",
    "    print(\"\\nüìã RUBRIC SCORES:\")\n",
    "    for criterion, details in eval_result['rubric_scores'].items():\n",
    "        score = details['score']\n",
    "        bar = \"‚ñà\" * score + \"‚ñë\" * (10 - score)\n",
    "        print(f\"\\n  {criterion.upper():<15} [{bar}] {score}/10\")\n",
    "        print(f\"  ‚îî‚îÄ {details['justification']}\")\n",
    "    \n",
    "    # Overall scores\n",
    "    print(f\"\\nüéØ OVERALL SCORES:\")\n",
    "    print(f\"  Raw Average:     {eval_result['raw_average']:.2f}/10\")\n",
    "    print(f\"  Weighted Score:  {eval_result['weighted_score']:.2f}/10\")\n",
    "    \n",
    "    if eval_result.get('reference_alignment'):\n",
    "        alignment = eval_result['reference_alignment']\n",
    "        bar = \"‚ñà\" * (alignment // 10) + \"‚ñë\" * (10 - alignment // 10)\n",
    "        print(f\"  Reference Match: [{bar}] {alignment}%\")\n",
    "    \n",
    "    # Strengths\n",
    "    print(f\"\\n‚úÖ STRENGTHS:\")\n",
    "    for strength in eval_result['strengths']:\n",
    "        print(f\"  ‚Ä¢ {strength}\")\n",
    "    \n",
    "    # Weaknesses\n",
    "    print(f\"\\n‚ö†Ô∏è  WEAKNESSES:\")\n",
    "    for weakness in eval_result['weaknesses']:\n",
    "        print(f\"  ‚Ä¢ {weakness}\")\n",
    "    \n",
    "    # Improvements\n",
    "    print(f\"\\nüí° IMPROVEMENT SUGGESTIONS:\")\n",
    "    for improvement in eval_result['improvements']:\n",
    "        print(f\"  ‚Ä¢ {improvement}\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    print(f\"\\nüìù OVERALL ASSESSMENT:\")\n",
    "    print(f\"  {eval_result['overall_assessment']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb7724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 4: MULTI-ASPECT JUDGE WITH REFERENCE ANSWERS\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 1: Evaluation with Reference Answer\n",
      "======================================================================\n",
      "\n",
      "‚ùì Question: What is gradient descent?\n",
      "\n",
      "üìö Reference Answer:\n",
      "Gradient descent is an optimization algorithm used to minimize \n",
      "    a cost function by iteratively moving in the direction of steepest descent \n",
      "    as defined by the negative of the gradient. It updates parameters by \n",
      "    subtracting the gradient multiplied by a learning rate.\n",
      "\n",
      "üí¨ Candidate Answer:\n",
      "Gradient descent is an optimization algorithm used to minimize a function by iteratively moving towards the lowest point of that function. It is widely used in machine learning and statistics, particularly for training models, such as linear regression and neural networks.\n",
      "\n",
      "### How It Works:\n",
      "\n",
      "1. **Objective Function**: You start with a cost function (or loss function) that measures how well a particular model fits the data. The goal is to minimize this function.\n",
      "\n",
      "2. **Initialization**: The algorithm begins with an initial guess for the parameters (weights) that you want to optimize.\n",
      "\n",
      "3. **Compute the Gradient**: For the current set of parameters, compute the gradient (the vector of partial derivatives) of the cost function with respect to the parameters. The gradient indicates the direction of the steepest ascent of the function.\n",
      "\n",
      "4. **Update the Parameters**: Adjust the parameters in the opposite direction of the gradient (hence \"descent\") to move towards the minimum. The adjustment is proportional to the gradient and controlled by a hyperparameter known as the learning rate (\\(\\alpha\\)):\n",
      "   \\[\n",
      "   \\theta = \\theta - \\alpha \\nabla J(\\theta)\n",
      "   \\]\n",
      "   Here, \\(\\theta\\) represents the parameters, \\(\\nabla J(\\theta)\\) is the gradient, and \\(\\alpha\\) is the learning rate.\n",
      "\n",
      "5. **Iterate**: Repeat steps 3 and 4 until convergence, i.e., until the change in the cost function is smaller than a pre-defined threshold or after a set number of iterations.\n",
      "\n",
      "### Variants:\n",
      "\n",
      "There are several variants of gradient descent, including:\n",
      "\n",
      "- **Batch Gradient Descent**: Uses the entire dataset to compute the gradient; can be computationally expensive for large datasets.\n",
      "  \n",
      "- **Stochastic Gradient Descent (SGD)**: Uses one sample (or a small batch, called mini-batch) to compute the gradient; this introduces noise but can help escape local minima and typically converges faster.\n",
      "\n",
      "- **Mini-batch Gradient Descent**: A compromise between batch and stochastic methods; it uses a small random subset of the training data to compute the gradient at each iteration.\n",
      "\n",
      "### Applications:\n",
      "\n",
      "Gradient descent is crucial in training various machine learning models, including linear regression, logistic regression, and neural networks. It efficiently finds the optimal parameters that minimize the error between predicted and actual values.\n",
      "\n",
      "### Challenges:\n",
      "\n",
      "- **Choosing Learning Rate**: If the learning rate is too high, the algorithm may overshoot the minimum; if too low, it may take a long time to converge.\n",
      "\n",
      "- **Local Minima/Saddle Points**: In complex, high-dimensional spaces (e.g., neural networks), the cost function might have multiple local minima, which can trap the optimization process.\n",
      "\n",
      "Overall, gradient descent is a foundational technique in optimization that plays a vital role in the field of machine learning.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìä DETAILED EVALUATION REPORT\n",
      "======================================================================\n",
      "\n",
      "üìã RUBRIC SCORES:\n",
      "\n",
      "  ACCURACY        [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10/10\n",
      "  ‚îî‚îÄ The explanation is fully accurate, properly describing gradient descent as an optimization algorithm, the role of the gradient, parameter update, and use in machine learning.\n",
      "\n",
      "  COMPLETENESS    [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10/10\n",
      "  ‚îî‚îÄ The answer covers all important aspects, including definition, process steps, formula, variants, practical challenges, and applications.\n",
      "\n",
      "  CLARITY         [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 9/10\n",
      "  ‚îî‚îÄ The answer is clear, uses appropriate headings and explanation, though very introductory readers may find a couple terms (like 'partial derivatives') slightly advanced without deeper breakdown.\n",
      "\n",
      "  COHERENCE       [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10/10\n",
      "  ‚îî‚îÄ Each section logically follows the previous one; the answer is well-structured, starting with the basics and building up with details and variants.\n",
      "\n",
      "  CONCISENESS     [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 8/10\n",
      "  ‚îî‚îÄ Thoroughness leads to slight verbosity; some content (e.g., applications) could be condensed. No major redundancy, but room for trimming.\n",
      "\n",
      "üéØ OVERALL SCORES:\n",
      "  Raw Average:     9.40/10\n",
      "  Weighted Score:  9.56/10\n",
      "  Reference Match: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 95%\n",
      "\n",
      "‚úÖ STRENGTHS:\n",
      "  ‚Ä¢ Comprehensive explanation including advanced topics like variants and challenges\n",
      "  ‚Ä¢ Clear description of the algorithm steps and underlying concepts\n",
      "\n",
      "‚ö†Ô∏è  WEAKNESSES:\n",
      "  ‚Ä¢ Slightly verbose and could be condensed to focus on essentials\n",
      "  ‚Ä¢ Some terminology may require further simplification for novices\n",
      "\n",
      "üí° IMPROVEMENT SUGGESTIONS:\n",
      "  ‚Ä¢ Trim non-core details (e.g., separate applications or challenges into briefer notes or examples where relevant)\n",
      "  ‚Ä¢ Add a one-sentence summary at the start for immediate clarity, especially for newcomers\n",
      "\n",
      "üìù OVERALL ASSESSMENT:\n",
      "  This is an excellent, thorough answer with strong factual accuracy and coverage of all core concepts and relevant details of gradient descent. The logical organization and breakdown into steps and variants make it highly readable and useful for users who want both foundational and advanced understanding. While it could be more concise and simplified for absolute beginners, it closely matches‚Äîand expands on‚Äîthe reference, achieving a high level of alignment and value.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 2: Batch Evaluation\n",
      "======================================================================\n",
      "\n",
      "üìù Generating candidate answers...\n",
      "\n",
      "======================================================================\n",
      "QUESTION 1: What is overfitting?\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üìä DETAILED EVALUATION REPORT\n",
      "======================================================================\n",
      "\n",
      "üìã RUBRIC SCORES:\n",
      "\n",
      "  ACCURACY        [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10/10\n",
      "  ‚îî‚îÄ The answer provides a precise and correct definition of overfitting, describing both its nature (learning noise as well as patterns) and its consequences (good training, poor generalization).\n",
      "\n",
      "  COMPLETENESS    [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 9/10\n",
      "  ‚îî‚îÄ It covers not only the definition but also describes symptoms, causes, and prevention methods, giving a comprehensive explanation beyond the reference answer.\n",
      "\n",
      "  CLARITY         [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 9/10\n",
      "  ‚îî‚îÄ The answer is clearly structured, uses bullet points effectively, and explains concepts in a straightforward manner.\n",
      "\n",
      "  COHERENCE       [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10/10\n",
      "  ‚îî‚îÄ Ideas progress logically from definition, to characteristics, to mitigation strategies, maintaining excellent organization and flow.\n",
      "\n",
      "  CONCISENESS     [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 8/10\n",
      "  ‚îî‚îÄ While the answer is thorough, some information (especially about mitigation techniques) could be condensed for brevity, given the straightforward nature of the question.\n",
      "\n",
      "üéØ OVERALL SCORES:\n",
      "  Raw Average:     9.20/10\n",
      "  Weighted Score:  9.41/10\n",
      "  Reference Match: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 95%\n",
      "\n",
      "‚úÖ STRENGTHS:\n",
      "  ‚Ä¢ Accurate and technically precise explanation.\n",
      "  ‚Ä¢ Very comprehensive, including symptoms and solutions.\n",
      "  ‚Ä¢ Clearly structured and easy to follow.\n",
      "\n",
      "‚ö†Ô∏è  WEAKNESSES:\n",
      "  ‚Ä¢ Slightly verbose, particularly in the list of mitigation strategies.\n",
      "  ‚Ä¢ Could distill the core definition more succinctly before elaborating.\n",
      "  ‚Ä¢ Slightly more detail than needed for a basic answer.\n",
      "\n",
      "üí° IMPROVEMENT SUGGESTIONS:\n",
      "  ‚Ä¢ Condense mitigation strategies to a shorter summary or mention only key ones.\n",
      "  ‚Ä¢ Present the main definition upfront in one or two sentences before elaborating.\n",
      "  ‚Ä¢ Consider matching the detail to the question scope for succinctness.\n",
      "\n",
      "üìù OVERALL ASSESSMENT:\n",
      "  The candidate answer demonstrates a strong technical understanding of overfitting, offering a clear definition along with practical indicators and preventive techniques. It exceeds the reference in completeness and guidance for mitigation, making it highly educational. However, it slightly overshoots the brevity expected in typical answers to this question and could be improved by distilling the core idea before expanding with examples and strategies. Overall, it is an excellent and well-structured response with only minor issues of verbosity.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "QUESTION 2: Explain the bias-variance tradeoff\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üìä DETAILED EVALUATION REPORT\n",
      "======================================================================\n",
      "\n",
      "üìã RUBRIC SCORES:\n",
      "\n",
      "  ACCURACY        [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10/10\n",
      "  ‚îî‚îÄ The candidate answer is factually correct throughout, correctly describing both bias and variance, their causes and effects (underfitting, overfitting), and the core idea of trading off these sources of error in model selection. The mathematical relationship is mentioned, techniques like regularization and cross-validation are relevant.\n",
      "\n",
      "  COMPLETENESS    [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10/10\n",
      "  ‚îî‚îÄ The answer covers all main aspects expected: definitions of bias and variance, their effects (underfitting/overfitting), explanation of the tradeoff, approaches to address it, and the notion of overall error (including irreducible error). Far exceeds the brief reference answer in detail.\n",
      "\n",
      "  CLARITY         [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 9/10\n",
      "  ‚îî‚îÄ The explanation is clearly written, terms are well defined, examples are used effectively, and technical jargon is explained. The paragraph structure and headers improve readability. Could be slightly more succinct in some sections.\n",
      "\n",
      "  COHERENCE       [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 10/10\n",
      "  ‚îî‚îÄ The answer flows logically from definitions through to implications and strategies, with clear connections between ideas and well-sequenced sections.\n",
      "\n",
      "  CONCISENESS     [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 8/10\n",
      "  ‚îî‚îÄ The answer is somewhat long and repeats core ideas in several ways (e.g., examples provided for both bias and variance). Some wording could be more concise, but this is traded off for thoroughness.\n",
      "\n",
      "üéØ OVERALL SCORES:\n",
      "  Raw Average:     9.40/10\n",
      "  Weighted Score:  9.51/10\n",
      "  Reference Match: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 95%\n",
      "\n",
      "‚úÖ STRENGTHS:\n",
      "  ‚Ä¢ Very comprehensive explanation, includes practical strategies.\n",
      "  ‚Ä¢ Clear definitions and illustrative examples for both bias and variance.\n",
      "\n",
      "‚ö†Ô∏è  WEAKNESSES:\n",
      "  ‚Ä¢ Slightly verbose in places, could be more concise.\n",
      "  ‚Ä¢ Could mention more explicitly that the tradeoff is often visualized as a U-shaped curve of error vs. model complexity.\n",
      "\n",
      "üí° IMPROVEMENT SUGGESTIONS:\n",
      "  ‚Ä¢ Trim redundant or repetitive sentences for greater conciseness.\n",
      "  ‚Ä¢ Briefly mention (or illustrate) the curve of error versus model complexity to better contextualize the tradeoff.\n",
      "\n",
      "üìù OVERALL ASSESSMENT:\n",
      "  The candidate answer offers an accurate, well-structured, and thorough explanation of the bias-variance tradeoff, going well beyond the minimal standard set by the reference. Important concepts are defined, contextualized with examples, and practical balancing strategies are provided. Although slightly verbose, the prose remains clear and logically organized. A few minor tweaks for brevity or the inclusion of a mention/visualization of the U-shaped tradeoff curve would further enhance the answer. This response demonstrates a strong command of the topic and would be very helpful to learners new to the concept.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Batch evaluation complete!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PHASE 4: MULTI-ASPECT JUDGE WITH REFERENCE ANSWERS\")\n",
    "print(\"=\" * 70)\n",
    "    \n",
    "judge = MultiAspectJudge()\n",
    "    \n",
    "# Example 1: Evaluation with reference answer\n",
    "print(\"\\n\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE 1: Evaluation with Reference Answer\")\n",
    "print(\"=\" * 70)\n",
    "    \n",
    "question = \"What is gradient descent?\"\n",
    "    \n",
    "reference = \"\"\"Gradient descent is an optimization algorithm used to minimize \n",
    "    a cost function by iteratively moving in the direction of steepest descent \n",
    "    as defined by the negative of the gradient. It updates parameters by \n",
    "    subtracting the gradient multiplied by a learning rate.\"\"\"\n",
    "    \n",
    "# Generate a candidate answer\n",
    "candidate = judge.generate_answer(question)\n",
    "    \n",
    "print(f\"\\n‚ùì Question: {question}\\n\")\n",
    "print(f\"üìö Reference Answer:\\n{reference}\\n\")\n",
    "print(f\"üí¨ Candidate Answer:\\n{candidate}\\n\")\n",
    "    \n",
    "# Evaluate\n",
    "evaluation = judge.evaluate_with_reference(question, candidate, reference)\n",
    "print_detailed_evaluation(evaluation)\n",
    "    \n",
    "# Example 2: Batch evaluation\n",
    "print(\"\\n\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE 2: Batch Evaluation\")\n",
    "print(\"=\" * 70)\n",
    "    \n",
    "questions = [\n",
    "        \"What is overfitting?\",\n",
    "        \"Explain the bias-variance tradeoff\"\n",
    "    ]\n",
    "    \n",
    "print(\"\\nüìù Generating candidate answers...\")\n",
    "candidates = [judge.generate_answer(q) for q in questions]\n",
    "    \n",
    "references = [\n",
    "        \"Overfitting occurs when a model learns training data too well, including noise, reducing generalization to new data.\",\n",
    "        \"Bias-variance tradeoff: high bias models underfit (too simple), high variance models overfit (too complex). Goal is to balance both.\"\n",
    "    ]\n",
    "    \n",
    "results = judge.batch_evaluate(questions, candidates, references)\n",
    "    \n",
    "for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"QUESTION {i}: {result['question']}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print_detailed_evaluation(result['evaluation'])\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Batch evaluation complete!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
